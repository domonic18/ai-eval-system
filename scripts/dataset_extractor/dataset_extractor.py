#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®é›†è¯»å–å’Œå¯¼å‡ºè„šæœ¬
æ”¯æŒOpenCompassä¸­çš„å„ç§æ•°æ®é›†ï¼Œç‰¹åˆ«æ˜¯C-EVALæ•°æ®é›†
"""

import os
import sys
import csv
import json
import argparse
from pathlib import Path
from typing import Dict, List, Optional, Any
import pandas as pd

# ==================== é…ç½®å¸¸é‡ ====================
# æ•°æ®é›†ç›¸å…³é…ç½®
DEFAULT_DATASET_NAME = "ceval"
DEFAULT_OUTPUT_FORMAT = "both"  # excel, csv, both

# æ”¯æŒçš„æ•°æ®é›†åˆ—è¡¨
SUPPORTED_DATASETS = {
    "ceval": {
        "name": "C-EVAL",
        "type": "CEvalDataset",
        "paths": [
            "./cache/data/ceval/formal_ceval",
            "../workspace/opencompass/data/ceval/formal_ceval",
            "../../workspace/opencompass/data/ceval/formal_ceval",
            "~/.cache/opencompass/data/ceval/formal_ceval"
        ],
        "file_extension": "_val.csv",
        "fields": ['explanation', 'answer'],
        "subject_field": 'subject'
    },
    "ocnli": {
        "name": "FewCLUE/OCNLI",
        "type": "CMNLIDatasetV2", 
        "paths": [
            "./cache/data/FewCLUE/ocnli",
            "../workspace/opencompass/data/FewCLUE/ocnli",
            "../../workspace/opencompass/data/FewCLUE/ocnli",
            "~/.cache/opencompass/data/FewCLUE/ocnli"
        ],
        "file_extension": ".json",
        "fields": ['sentence1', 'sentence2', 'label'],
        "subject_field": None
    }
}

# è·¯å¾„é…ç½®
# OpenCompassåº“è·¯å¾„
OPENCOMPASS_LIB_PATH = os.path.join(os.path.dirname(__file__), '..', '..', 'libs', 'OpenCompass')

# æ•°æ®è·¯å¾„é…ç½® - æŒ‰ä¼˜å…ˆçº§æ’åº
CEVAL_DATA_PATHS = [
    "./cache/data/ceval/formal_ceval",                    # å½“å‰è„šæœ¬ç›®å½•ä¸‹çš„cache
    "../workspace/opencompass/data/ceval/formal_ceval",   # ä¸Šçº§workspaceç›®å½•
    "../../workspace/opencompass/data/ceval/formal_ceval", # ä¸Šä¸Šçº§workspaceç›®å½•
    "~/.cache/opencompass/data/ceval/formal_ceval"        # ç”¨æˆ·ç¼“å­˜ç›®å½•
]

# ç¯å¢ƒå˜é‡é…ç½®
ENV_DATASET_SOURCE = "Local"
ENV_COMPASS_DATA_CACHE = "./cache"

# æ–‡ä»¶æ‰©å±•åé…ç½®
CSV_EXTENSION = "_val.csv"
EXCEL_EXTENSION = ".xlsx"
CSV_EXTENSION_OUT = ".csv"

# æ•°æ®åˆ†å‰²é…ç½®
DEFAULT_SPLIT = "val"
TRAIN_SPLIT = "dev"
TEST_SPLIT = "test"

# è¾“å‡ºæ–‡ä»¶å‘½åé…ç½®
ALL_SUBJECTS_FILENAME = "ceval_all_subjects_data"
SUBJECT_FILENAME_PREFIX = "ceval_{}_data"

# Excelå·¥ä½œè¡¨åç§°é…ç½®
ALL_SUBJECTS_SHEET_NAME = "C-EVAL_All_Subjects"
SUBJECT_SHEET_NAME_PREFIX = "C-EVAL_{}"

# æ•°æ®å­—æ®µé…ç½®
DEFAULT_FIELDS = ['explanation', 'answer']
SUBJECT_FIELD_NAME = 'subject'

# ==================== å¯¼å…¥æ¨¡å— ====================
# æ·»åŠ OpenCompassè·¯å¾„
sys.path.insert(0, OPENCOMPASS_LIB_PATH)

try:
    from opencompass.utils import get_data_path
    from opencompass.datasets.ceval import CEvalDataset
    OPENCOMPASS_AVAILABLE = True
except ImportError:
    print("è­¦å‘Š: OpenCompassæ¨¡å—å¯¼å…¥å¤±è´¥ï¼Œå°†ä½¿ç”¨åŸºç¡€CSVè¯»å–åŠŸèƒ½")
    OPENCOMPASS_AVAILABLE = False


class DatasetExtractor:
    """æ•°æ®é›†æå–å™¨åŸºç±»"""
    
    def __init__(self, dataset_name: str):
        """
        åˆå§‹åŒ–æ•°æ®é›†æå–å™¨
        
        Args:
            dataset_name: æ•°æ®é›†åç§°ï¼Œå¦‚ 'ceval', 'ocnli'
        """
        self.dataset_name = dataset_name
        
        # éªŒè¯æ•°æ®é›†æ˜¯å¦æ”¯æŒ
        if dataset_name not in SUPPORTED_DATASETS:
            raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®é›†: {dataset_name}ã€‚æ”¯æŒçš„æ•°æ®é›†: {list(SUPPORTED_DATASETS.keys())}")
        
        # è·å–æ•°æ®é›†é…ç½®
        self.dataset_config = SUPPORTED_DATASETS[dataset_name]
        self.dataset_type = self.dataset_config["type"]
        self.dataset_paths = self.dataset_config["paths"]
        self.file_extension = self.dataset_config["file_extension"]
        self.fields = self.dataset_config["fields"]
        self.subject_field = self.dataset_config["subject_field"]
        
        # è®¾ç½®è¾“å‡ºç›®å½•
        self.output_dir = Path(f"./{dataset_name}")
        self.output_dir.mkdir(exist_ok=True)
        
        print(f"âœ… åˆå§‹åŒ– {self.dataset_config['name']} æ•°æ®é›†æå–å™¨")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_dir.absolute()}")
        
    def extract_dataset(self, dataset_name: str, **kwargs) -> bool:
        """
        æå–æ•°æ®é›†
        
        Args:
            dataset_name: æ•°æ®é›†åç§°
            **kwargs: å…¶ä»–å‚æ•°
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            # æ ¹æ®æ•°æ®é›†ç±»å‹è°ƒç”¨ç›¸åº”çš„æå–é€»è¾‘
            if dataset_name == "ceval":
                return self._extract_ceval_dataset(**kwargs)
            elif dataset_name == "ocnli":
                return self._extract_ocnli_dataset(**kwargs)
            else:
                print(f"âŒ ä¸æ”¯æŒçš„æ•°æ®é›†ç±»å‹: {dataset_name}")
                return False
        except Exception as e:
            print(f"âŒ æå–æ•°æ®é›†æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False
    
    def save_to_excel(self, data: List[Dict], filename: str, sheet_name: str = "Sheet1"):
        """ä¿å­˜æ•°æ®åˆ°Excelæ–‡ä»¶"""
        try:
            df = pd.DataFrame(data)
            filepath = self.output_dir / filename
            
            with pd.ExcelWriter(filepath, engine='openpyxl') as writer:
                df.to_excel(writer, sheet_name=sheet_name, index=False)
            
            print(f"âœ… Excelæ–‡ä»¶ä¿å­˜æˆåŠŸ: {filepath}")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜Excelæ–‡ä»¶å¤±è´¥: {e}")
    
    def save_to_csv(self, data: List[Dict], filename: str):
        """ä¿å­˜æ•°æ®åˆ°CSVæ–‡ä»¶"""
        try:
            df = pd.DataFrame(data)
            filepath = self.output_dir / filename
            
            df.to_csv(filepath, index=False, encoding='utf-8')
            print(f"âœ… CSVæ–‡ä»¶ä¿å­˜æˆåŠŸ: {filepath}")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜CSVæ–‡ä»¶å¤±è´¥: {e}")
    
    def _find_data_path(self) -> Optional[str]:
        """
        æŸ¥æ‰¾æ•°æ®é›†çš„æ ¹ç›®å½•è·¯å¾„
        
        Returns:
            str: æ‰¾åˆ°çš„æ ¹ç›®å½•è·¯å¾„ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›None
        """
        for path in self.dataset_paths:
            expanded_path = os.path.expanduser(path)
            if os.path.exists(expanded_path):
                return expanded_path
        return None
    
    def _extract_ceval_dataset(self, **kwargs) -> bool:
        """æå–C-EVALæ•°æ®é›†çš„åŸºç¡€æ–¹æ³•"""
        print(f"ğŸ”„ å¼€å§‹æå– {self.dataset_config['name']} æ•°æ®é›†...")
        # è¿™é‡Œå¯ä»¥æ·»åŠ C-EVALçš„é€šç”¨æå–é€»è¾‘
        return False
    
    def _extract_ocnli_dataset(self, **kwargs) -> bool:
        """
        æå–OCNLIæ•°æ®é›†
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        print(f"\nğŸ”„ å¼€å§‹æå– {self.dataset_config['name']} æ•°æ®é›†...")
        
        # æŸ¥æ‰¾æ•°æ®æ–‡ä»¶
        data_path = self._find_data_path()
        if not data_path:
            print(f"âŒ æ‰¾ä¸åˆ° {self.dataset_config['name']} æ•°æ®ç›®å½•")
            return False
        
        print(f"ğŸ“‚ æ‰¾åˆ°æ•°æ®ç›®å½•: {data_path}")
        
        # è¯»å–æ•°æ®æ–‡ä»¶
        data_files = []
        for split in ['dev_few_all', 'test_public']:
            file_path = os.path.join(data_path, f"{split}.json")
            if os.path.exists(file_path):
                data_files.append((split, file_path))
        
        if not data_files:
            print(f"âŒ åœ¨ {data_path} ä¸­æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶")
            return False
        
        all_data = []
        
        # å¤„ç†æ¯ä¸ªæ•°æ®æ–‡ä»¶
        for split_name, file_path in data_files:
            print(f"ğŸ“– æ­£åœ¨è¯»å– {split_name} æ•°æ®...")
            
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    split_data = []
                    for line_num, line in enumerate(f, 1):
                        try:
                            item = json.loads(line.strip())
                            # æ·»åŠ åˆ†å‰²ä¿¡æ¯
                            item['split'] = split_name
                            split_data.append(item)
                        except json.JSONDecodeError as e:
                            print(f"âš ï¸  ç¬¬ {line_num} è¡ŒJSONè§£æé”™è¯¯: {e}")
                            continue
                    
                    print(f"âœ… {split_name} æ•°æ®è¯»å–å®Œæˆï¼Œå…± {len(split_data)} æ¡è®°å½•")
                    all_data.extend(split_data)
                    
            except Exception as e:
                print(f"âŒ è¯»å– {file_path} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                continue
        
        if not all_data:
            print("âŒ æ²¡æœ‰è¯»å–åˆ°ä»»ä½•æ•°æ®")
            return False
        
        print(f"ğŸ“Š æ€»å…±è¯»å–åˆ° {len(all_data)} æ¡è®°å½•")
        
        # ä¿å­˜æ•°æ®
        return self._save_ocnli_data(all_data)
    
    def _save_ocnli_data(self, data: List[Dict]) -> bool:
        """
        ä¿å­˜OCNLIæ•°æ®
        
        Args:
            data: æ•°æ®åˆ—è¡¨
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            # åˆ›å»ºDataFrame
            df = pd.DataFrame(data)
            
            # é‡æ–°æ’åˆ—åˆ—é¡ºåº
            columns = ['split', 'sentence1', 'sentence2', 'label']
            # æ·»åŠ å…¶ä»–å¯èƒ½å­˜åœ¨çš„åˆ—
            for col in df.columns:
                if col not in columns:
                    columns.append(col)
            
            df = df[columns]
            
            # ä¿å­˜ä¸ºExcel
            excel_filename = f"ocnli_data{EXCEL_EXTENSION}"
            excel_path = self.output_dir / excel_filename
            
            with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
                # æ‰€æœ‰æ•°æ®å·¥ä½œè¡¨
                df.to_excel(writer, sheet_name='OCNLI_All_Data', index=False)
                
                # æŒ‰åˆ†å‰²åˆ†ç»„çš„å·¥ä½œè¡¨
                for split in df['split'].unique():
                    split_df = df[df['split'] == split]
                    sheet_name = f'OCNLI_{split.replace("_", " ").title()}'
                    # Excelå·¥ä½œè¡¨åç§°é™åˆ¶ä¸º31ä¸ªå­—ç¬¦
                    if len(sheet_name) > 31:
                        sheet_name = sheet_name[:31]
                    split_df.to_excel(writer, sheet_name=sheet_name, index=False)
            
            print(f"âœ… Excelæ–‡ä»¶ä¿å­˜æˆåŠŸ: {excel_path}")
            
            # ä¿å­˜ä¸ºCSV
            csv_filename = f"ocnli_data{CSV_EXTENSION_OUT}"
            csv_path = self.output_dir / csv_filename
            df.to_csv(csv_path, index=False, encoding='utf-8')
            print(f"âœ… CSVæ–‡ä»¶ä¿å­˜æˆåŠŸ: {csv_path}")
            
            # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
            print(f"\nğŸ“ˆ æ•°æ®ç»Ÿè®¡:")
            print(f"   æ€»è®°å½•æ•°: {len(data)}")
            print(f"   åˆ†å‰²åˆ†å¸ƒ:")
            for split in df['split'].unique():
                count = len(df[df['split'] == split])
                print(f"     {split}: {count} æ¡")
            
            print(f"   æ ‡ç­¾åˆ†å¸ƒ:")
            for label in df['label'].unique():
                count = len(df[df['label'] == label])
                print(f"     {label}: {count} æ¡")
            
            return True
            
        except Exception as e:
            print(f"âŒ ä¿å­˜æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False


class CEvalExtractor(DatasetExtractor):
    """C-EVALæ•°æ®é›†æå–å™¨"""
    
    def __init__(self, dataset_name: str = DEFAULT_DATASET_NAME):
        super().__init__(dataset_name)
        self.dataset_path = None
        
    def extract_dataset(self, dataset_name: str = DEFAULT_DATASET_NAME, **kwargs) -> bool:
        """æå–C-EVALæ•°æ®é›†"""
        print(f"å¼€å§‹æå–C-EVALæ•°æ®é›†: {dataset_name}")
        
        # å°è¯•è·å–æ•°æ®é›†è·¯å¾„
        if OPENCOMPASS_AVAILABLE:
            try:
                # è®¾ç½®ç¯å¢ƒå˜é‡ä»¥ä½¿ç”¨æœ¬åœ°æ¨¡å¼
                os.environ['DATASET_SOURCE'] = ENV_DATASET_SOURCE
                os.environ['COMPASS_DATA_CACHE'] = ENV_COMPASS_DATA_CACHE
                
                # è·å–æ•°æ®è·¯å¾„
                self.dataset_path = get_data_path("opencompass/ceval-exam", local_mode=True)
                print(f"æ•°æ®é›†è·¯å¾„: {self.dataset_path}")
                
                # ä½¿ç”¨OpenCompassçš„CEvalDatasetåŠ è½½æ•°æ®
                return self._extract_with_opencompass(dataset_name)
                
            except Exception as e:
                print(f"ä½¿ç”¨OpenCompassåŠ è½½å¤±è´¥: {e}")
                print("å°è¯•ç›´æ¥è¯»å–CSVæ–‡ä»¶...")
        
        # å›é€€åˆ°ç›´æ¥CSVè¯»å–
        return self._extract_from_csv(dataset_name)
    
    def _extract_with_opencompass(self, dataset_name: str) -> bool:
        """ä½¿ç”¨OpenCompassåŠ è½½æ•°æ®é›†"""
        try:
            # åŠ è½½æ•°æ®é›†
            dataset = CEvalDataset.load(self.dataset_path, dataset_name)
            
            if DEFAULT_SPLIT not in dataset:
                print(f"è­¦å‘Š: {DEFAULT_SPLIT}é›†ä¸å­˜åœ¨")
                return False
            
            val_data = dataset[DEFAULT_SPLIT]
            print(f"æˆåŠŸåŠ è½½{DEFAULT_SPLIT}é›†ï¼Œå…± {len(val_data)} æ¡æ•°æ®")
            
            # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
            data_list = []
            for i in range(len(val_data)):
                item = val_data[i]
                data_list.append({
                    'id': i,
                    'question': item.get('question', ''),
                    'A': item.get('A', ''),
                    'B': item.get('B', ''),
                    'C': item.get('C', ''),
                    'D': item.get('D', ''),
                    'answer': item.get('answer', ''),
                    'explanation': item.get('explanation', ''),
                    'subject': dataset_name
                })
            
            # ä¿å­˜åˆ°Excel
            excel_filename = f"{SUBJECT_FILENAME_PREFIX.format(dataset_name)}{EXCEL_EXTENSION}"
            self.save_to_excel(data_list, excel_filename, f"{SUBJECT_SHEET_NAME_PREFIX.format(dataset_name)}")
            
            # ä¿å­˜åˆ°CSV
            csv_filename = f"{SUBJECT_FILENAME_PREFIX.format(dataset_name)}{CSV_EXTENSION_OUT}"
            self.save_to_csv(data_list, csv_filename)
            
            return True
            
        except Exception as e:
            print(f"OpenCompassæ•°æ®åŠ è½½å¤±è´¥: {e}")
            return False
    
    def _extract_from_csv(self, dataset_name: str) -> bool:
        """ç›´æ¥ä»CSVæ–‡ä»¶è¯»å–æ•°æ®"""
        # å°è¯•å¤šä¸ªå¯èƒ½çš„è·¯å¾„
        data_path = None
        for path in CEVAL_DATA_PATHS:
            expanded_path = os.path.expanduser(path)
            if os.path.exists(expanded_path):
                data_path = expanded_path
                break
        
        if not data_path:
            print("é”™è¯¯: æ‰¾ä¸åˆ°C-EVALæ•°æ®ç›®å½•")
            return False
        
        print(f"ä½¿ç”¨æ•°æ®è·¯å¾„: {data_path}")
        
        # è¯»å–æ‰€æœ‰ç§‘ç›®çš„æ•°æ®
        all_data = []
        subjects = []
        
        # è·å–æ‰€æœ‰ç§‘ç›®
        val_dir = os.path.join(data_path, DEFAULT_SPLIT)
        if os.path.exists(val_dir):
            for filename in os.listdir(val_dir):
                if filename.endswith(CSV_EXTENSION):
                    subject = filename.replace(CSV_EXTENSION, '')
                    subjects.append(subject)
        
        print(f"æ‰¾åˆ° {len(subjects)} ä¸ªç§‘ç›®")
        
        # è¯»å–æ¯ä¸ªç§‘ç›®çš„æ•°æ®
        for subject in subjects:
            csv_file = os.path.join(val_dir, f"{subject}{CSV_EXTENSION}")
            if os.path.exists(csv_file):
                try:
                    with open(csv_file, 'r', encoding='utf-8') as f:
                        reader = csv.DictReader(f)
                        for row in reader:
                            row[SUBJECT_FIELD_NAME] = subject
                            all_data.append(row)
                    print(f"å·²è¯»å–ç§‘ç›® {subject}: {len([d for d in all_data if d[SUBJECT_FIELD_NAME] == subject])} æ¡æ•°æ®")
                except Exception as e:
                    print(f"è¯»å–ç§‘ç›® {subject} å¤±è´¥: {e}")
        
        if not all_data:
            print("é”™è¯¯: æ²¡æœ‰è¯»å–åˆ°ä»»ä½•æ•°æ®")
            return False
        
        print(f"æ€»å…±è¯»å–åˆ° {len(all_data)} æ¡æ•°æ®")
        
        # ä¿å­˜åˆ°Excel
        excel_filename = f"{ALL_SUBJECTS_FILENAME}{EXCEL_EXTENSION}"
        self.save_to_excel(all_data, excel_filename, ALL_SUBJECTS_SHEET_NAME)
        
        # ä¿å­˜åˆ°CSV
        csv_filename = f"{ALL_SUBJECTS_FILENAME}{CSV_EXTENSION_OUT}"
        self.save_to_csv(all_data, csv_filename)
        
        # æŒ‰ç§‘ç›®åˆ†åˆ«ä¿å­˜
        for subject in subjects:
            subject_data = [d for d in all_data if d[SUBJECT_FIELD_NAME] == subject]
            if subject_data:
                subject_excel = f"{SUBJECT_FILENAME_PREFIX.format(subject)}{EXCEL_EXTENSION}"
                self.save_to_excel(subject_data, subject_excel, f"{SUBJECT_SHEET_NAME_PREFIX.format(subject)}")
                
                subject_csv = f"{SUBJECT_FILENAME_PREFIX.format(subject)}{CSV_EXTENSION_OUT}"
                self.save_to_csv(subject_data, subject_csv)
        
        return True


class GenericDatasetExtractor(DatasetExtractor):
    """é€šç”¨æ•°æ®é›†æå–å™¨"""
    
    def __init__(self, dataset_name: str = DEFAULT_DATASET_NAME):
        super().__init__(dataset_name)
    
    def extract_dataset(self, dataset_name: str, **kwargs) -> bool:
        """æå–é€šç”¨æ•°æ®é›†"""
        print(f"å¼€å§‹æå–æ•°æ®é›†: {dataset_name}")
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ å¯¹å…¶ä»–æ•°æ®é›†çš„æ”¯æŒ
        # ä¾‹å¦‚ï¼šMMLUã€AGIEvalç­‰
        
        print(f"æ•°æ®é›† {dataset_name} çš„æå–åŠŸèƒ½å°šæœªå®ç°")
        return False


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="OpenCompassæ•°æ®é›†æå–å·¥å…·")
    parser.add_argument("--dataset", "-d", default=DEFAULT_DATASET_NAME, 
                       help=f"æ•°æ®é›†åç§° (é»˜è®¤: {DEFAULT_DATASET_NAME})")
    parser.add_argument("--format", "-f", choices=["excel", "csv", "both"], 
                       default=DEFAULT_OUTPUT_FORMAT, help=f"è¾“å‡ºæ ¼å¼ (é»˜è®¤: {DEFAULT_OUTPUT_FORMAT})")
    
    args = parser.parse_args()
    
    # æ ¹æ®æ•°æ®é›†ç±»å‹é€‰æ‹©æå–å™¨
    if args.dataset.lower() == DEFAULT_DATASET_NAME:
        extractor = CEvalExtractor(args.dataset)
    else:
        extractor = GenericDatasetExtractor(args.dataset)
    
    # æå–æ•°æ®é›†
    success = extractor.extract_dataset(args.dataset)
    
    if success:
        print(f"\næ•°æ®é›† {args.dataset} æå–å®Œæˆï¼")
        print(f"è¾“å‡ºç›®å½•: {extractor.output_dir.absolute()}")
    else:
        print(f"\næ•°æ®é›† {args.dataset} æå–å¤±è´¥ï¼")
        sys.exit(1)


if __name__ == "__main__":
    main()
