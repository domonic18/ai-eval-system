#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
OCNLIæ•°æ®é›†å¤„ç†å™¨
"""

import os
import json
from typing import List, Dict, Optional
import pandas as pd
import sys

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ä»¥å¯¼å…¥configæ¨¡å—
sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))
from config import EXCEL_EXTENSION, CSV_EXTENSION_OUT
from processors.base import BaseDatasetProcessor


class OCNLIProcessor(BaseDatasetProcessor):
    """OCNLIæ•°æ®é›†å¤„ç†å™¨"""
    
    def __init__(self, dataset_name: str = "ocnli"):
        super().__init__(dataset_name)
    
    def process(self, **kwargs) -> bool:
        """
        å¤„ç†OCNLIæ•°æ®é›†
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        print(f"ğŸ”„ å¼€å§‹æå– {self.config['name']} æ•°æ®é›†...")
        
        # æŸ¥æ‰¾æ•°æ®è·¯å¾„
        data_path = self.find_data_path()
        if not data_path:
            print(f"âŒ æ‰¾ä¸åˆ° {self.config['name']} æ•°æ®ç›®å½•")
            return False
        
        print(f"ğŸ“‚ æ‰¾åˆ°æ•°æ®ç›®å½•: {data_path}")
        
        # è¯»å–æ•°æ®æ–‡ä»¶
        data_files = self._get_data_files(data_path)
        if not data_files:
            print(f"âŒ åœ¨ {data_path} ä¸­æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶")
            return False
        
        # å¤„ç†æ•°æ®
        all_data = self._process_data_files(data_files)
        if not all_data:
            print("âŒ æ²¡æœ‰è¯»å–åˆ°ä»»ä½•æ•°æ®")
            return False
        
        print(f"ğŸ“Š æ€»å…±è¯»å–åˆ° {len(all_data)} æ¡è®°å½•")
        
        # ä¿å­˜æ•°æ®
        return self._save_data(all_data)
    
    def find_data_path(self) -> Optional[str]:
        """æŸ¥æ‰¾OCNLIæ•°æ®è·¯å¾„"""
        return self._find_data_path_from_config()
    
    def _get_data_files(self, data_path: str) -> List[tuple]:
        """è·å–æ•°æ®æ–‡ä»¶åˆ—è¡¨"""
        data_files = []
        for split in ['dev_few_all', 'test_public']:
            file_path = os.path.join(data_path, f"{split}.json")
            if os.path.exists(file_path):
                data_files.append((split, file_path))
        
        return data_files
    
    def _process_data_files(self, data_files: List[tuple]) -> List[Dict]:
        """å¤„ç†æ‰€æœ‰æ•°æ®æ–‡ä»¶"""
        all_data = []
        
        for split_name, file_path in data_files:
            print(f"ğŸ“– æ­£åœ¨è¯»å– {split_name} æ•°æ®...")
            
            try:
                split_data = self._read_json_file(file_path, split_name)
                if split_data:
                    all_data.extend(split_data)
                    print(f"âœ… {split_name} æ•°æ®è¯»å–å®Œæˆï¼Œå…± {len(split_data)} æ¡è®°å½•")
                    
            except Exception as e:
                print(f"âŒ è¯»å– {file_path} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                continue
        
        return all_data
    
    def _read_json_file(self, file_path: str, split_name: str) -> List[Dict]:
        """è¯»å–JSONæ–‡ä»¶"""
        split_data = []
        
        with open(file_path, 'r', encoding='utf-8') as f:
            for line_num, line in enumerate(f, 1):
                try:
                    item = json.loads(line.strip())
                    # æ·»åŠ åˆ†å‰²ä¿¡æ¯
                    item['split'] = split_name
                    split_data.append(item)
                except json.JSONDecodeError as e:
                    print(f"âš ï¸  ç¬¬ {line_num} è¡ŒJSONè§£æé”™è¯¯: {e}")
                    continue
        
        return split_data
    
    def _save_data(self, data: List[Dict]) -> bool:
        """ä¿å­˜OCNLIæ•°æ®"""
        try:
            # åˆ›å»ºDataFrame
            df = pd.DataFrame(data)
            
            # é‡æ–°æ’åˆ—åˆ—é¡ºåº
            columns = ['split', 'sentence1', 'sentence2', 'label']
            # æ·»åŠ å…¶ä»–å¯èƒ½å­˜åœ¨çš„åˆ—
            for col in df.columns:
                if col not in columns:
                    columns.append(col)
            
            df = df[columns]
            
            # ä¿å­˜ä¸ºExcel
            excel_filename = f"ocnli_data{EXCEL_EXTENSION}"
            excel_path = self.output_dir / excel_filename
            
            with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
                # æ‰€æœ‰æ•°æ®å·¥ä½œè¡¨
                df.to_excel(writer, sheet_name='OCNLI_All_Data', index=False)
                
                # æŒ‰åˆ†å‰²åˆ†ç»„çš„å·¥ä½œè¡¨
                for split in df['split'].unique():
                    split_df = df[df['split'] == split]
                    sheet_name = f'OCNLI_{split.replace("_", " ").title()}'
                    # Excelå·¥ä½œè¡¨åç§°é™åˆ¶ä¸º31ä¸ªå­—ç¬¦
                    if len(sheet_name) > 31:
                        sheet_name = sheet_name[:31]
                    split_df.to_excel(writer, sheet_name=sheet_name, index=False)
            
            print(f"âœ… Excelæ–‡ä»¶ä¿å­˜æˆåŠŸ: {excel_path}")
            
            # ä¿å­˜ä¸ºCSV
            csv_filename = f"ocnli_data{CSV_EXTENSION_OUT}"
            csv_path = self.output_dir / csv_filename
            df.to_csv(csv_path, index=False, encoding='utf-8')
            print(f"âœ… CSVæ–‡ä»¶ä¿å­˜æˆåŠŸ: {csv_path}")
            
            # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
            print(f"\nğŸ“ˆ æ•°æ®ç»Ÿè®¡:")
            print(f"   æ€»è®°å½•æ•°: {len(data)}")
            print(f"   åˆ†å‰²åˆ†å¸ƒ:")
            for split in df['split'].unique():
                count = len(df[df['split'] == split])
                print(f"     {split}: {count} æ¡")
            
            print(f"   æ ‡ç­¾åˆ†å¸ƒ:")
            for label in df['label'].unique():
                count = len(df[df['label'] == label])
                print(f"     {label}: {count} æ¡")
            
            return True
            
        except Exception as e:
            print(f"âŒ ä¿å­˜æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False
