#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
TruthfulQAæ•°æ®é›†å¤„ç†å™¨
"""

import os
import json
from typing import List, Dict, Optional
import pandas as pd
import sys

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ä»¥å¯¼å…¥configæ¨¡å—
sys.path.insert(0, os.path.dirname(os.path.dirname(__file__)))
from config import EXCEL_EXTENSION, CSV_EXTENSION_OUT
from processors.base import BaseDatasetProcessor


class TruthfulQAProcessor(BaseDatasetProcessor):
    """TruthfulQAæ•°æ®é›†å¤„ç†å™¨"""
    
    def __init__(self, dataset_name: str = "truthfulqa"):
        super().__init__(dataset_name)
    
    def process(self, **kwargs) -> bool:
        """
        å¤„ç†TruthfulQAæ•°æ®é›†
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        print(f"ğŸ”„ å¼€å§‹æå– {self.config['name']} æ•°æ®é›†...")
        
        # æŸ¥æ‰¾æ•°æ®è·¯å¾„
        data_path = self.find_data_path()
        if not data_path:
            print(f"âŒ æ‰¾ä¸åˆ° {self.config['name']} æ•°æ®ç›®å½•")
            return False
        
        print(f"ğŸ“‚ æ‰¾åˆ°æ•°æ®ç›®å½•: {data_path}")
        
        # è¯»å–æ•°æ®æ–‡ä»¶
        data_files = self._get_data_files(data_path)
        if not data_files:
            print(f"âŒ åœ¨ {data_path} ä¸­æ‰¾ä¸åˆ°æ•°æ®æ–‡ä»¶")
            return False
        
        # å¤„ç†æ•°æ®
        all_data = self._process_data_files(data_files)
        if not all_data:
            print("âŒ æ²¡æœ‰è¯»å–åˆ°ä»»ä½•æ•°æ®")
            return False
        
        print(f"ğŸ“Š æ€»å…±è¯»å–åˆ° {len(all_data)} æ¡è®°å½•")
        
        # ä¿å­˜æ•°æ®
        return self._save_data(all_data)
    
    def find_data_path(self) -> Optional[str]:
        """æŸ¥æ‰¾TruthfulQAæ•°æ®è·¯å¾„"""
        return self._find_data_path_from_config()
    
    def _get_data_files(self, data_path: str) -> List[tuple]:
        """è·å–æ•°æ®æ–‡ä»¶åˆ—è¡¨"""
        data_files = []
        
        # TruthfulQAé€šå¸¸æœ‰validationå’Œteståˆ†å‰²
        for split in ['validation', 'test']:
            # å°è¯•ä¸åŒçš„æ–‡ä»¶æ ¼å¼
            for ext in ['.json', '.jsonl', '.csv']:
                file_path = os.path.join(data_path, f"{split}{ext}")
                if os.path.exists(file_path):
                    data_files.append((split, file_path, ext))
                    break
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ–‡ä»¶ï¼Œå°è¯•ç›´æ¥è¯»å–ç›®å½•
            split_dir = os.path.join(data_path, split)
            if os.path.isdir(split_dir):
                # æŸ¥æ‰¾ç›®å½•ä¸­çš„æ–‡ä»¶
                for filename in os.listdir(split_dir):
                    if filename.endswith(('.json', '.jsonl', '.csv')):
                        file_path = os.path.join(split_dir, filename)
                        data_files.append((split, file_path, os.path.splitext(filename)[1]))
                        break
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ†å‰²æ–‡ä»¶ï¼Œå°è¯•ç›´æ¥è¯»å–æ ¹ç›®å½•æ–‡ä»¶
        if not data_files:
            for filename in os.listdir(data_path):
                if filename.endswith(('.json', '.jsonl', '.csv')):
                    file_path = os.path.join(data_path, filename)
                    split_name = os.path.splitext(filename)[0]
                    data_files.append((split_name, file_path, os.path.splitext(filename)[1]))
        
        return data_files
    
    def _process_data_files(self, data_files: List[tuple]) -> List[Dict]:
        """å¤„ç†æ‰€æœ‰æ•°æ®æ–‡ä»¶"""
        all_data = []
        
        for split_name, file_path, file_ext in data_files:
            print(f"ğŸ“– æ­£åœ¨è¯»å– {split_name} æ•°æ®...")
            
            try:
                split_data = self._read_data_file(file_path, split_name, file_ext)
                if split_data:
                    all_data.extend(split_data)
                    print(f"âœ… {split_name} æ•°æ®è¯»å–å®Œæˆï¼Œå…± {len(split_data)} æ¡è®°å½•")
                    
            except Exception as e:
                print(f"âŒ è¯»å– {file_path} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                continue
        
        return all_data
    
    def _read_data_file(self, file_path: str, split_name: str, file_ext: str) -> List[Dict]:
        """è¯»å–æ•°æ®æ–‡ä»¶"""
        data = []
        
        try:
            if file_ext == '.json':
                # è¯»å–JSONæ–‡ä»¶
                with open(file_path, 'r', encoding='utf-8') as f:
                    if file_path.endswith('.jsonl'):
                        # JSONLæ ¼å¼ï¼Œæ¯è¡Œä¸€ä¸ªJSON
                        for line_num, line in enumerate(f, 1):
                            try:
                                item = json.loads(line.strip())
                                item['split'] = split_name
                                data.append(item)
                            except json.JSONDecodeError as e:
                                print(f"âš ï¸  ç¬¬ {line_num} è¡ŒJSONè§£æé”™è¯¯: {e}")
                                continue
                    else:
                        # æ ‡å‡†JSONæ ¼å¼
                        content = json.load(f)
                        if isinstance(content, list):
                            for item in content:
                                item['split'] = split_name
                                data.append(item)
                        elif isinstance(content, dict) and 'data' in content:
                            for item in content['data']:
                                item['split'] = split_name
                                data.append(item)
                        else:
                            print(f"âš ï¸  æœªçŸ¥çš„JSONæ ¼å¼: {type(content)}")
                            
            elif file_ext == '.csv':
                # è¯»å–CSVæ–‡ä»¶
                df = pd.read_csv(file_path, encoding='utf-8')
                for _, row in df.iterrows():
                    item = row.to_dict()
                    item['split'] = split_name
                    data.append(item)
            
        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶ {file_path} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
        
        return data
    
    def _save_data(self, data: List[Dict]) -> bool:
        """ä¿å­˜TruthfulQAæ•°æ®"""
        try:
            # åˆ›å»ºDataFrame
            df = pd.DataFrame(data)
            
            # é‡æ–°æ’åˆ—åˆ—é¡ºåºï¼Œå°†é‡è¦å­—æ®µæ”¾åœ¨å‰é¢
            priority_columns = ['split', 'question', 'best_answer']
            other_columns = [col for col in df.columns if col not in priority_columns]
            columns = priority_columns + other_columns
            
            df = df[columns]
            
            # ä¿å­˜ä¸ºExcel
            excel_filename = f"truthfulqa_data{EXCEL_EXTENSION}"
            excel_path = self.output_dir / excel_filename
            
            with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
                # æ‰€æœ‰æ•°æ®å·¥ä½œè¡¨
                df.to_excel(writer, sheet_name='TruthfulQA_All_Data', index=False)
                
                # æŒ‰åˆ†å‰²åˆ†ç»„çš„å·¥ä½œè¡¨
                for split in df['split'].unique():
                    split_df = df[df['split'] == split]
                    sheet_name = f'TruthfulQA_{split.title()}'
                    # Excelå·¥ä½œè¡¨åç§°é™åˆ¶ä¸º31ä¸ªå­—ç¬¦
                    if len(sheet_name) > 31:
                        sheet_name = sheet_name[:31]
                    split_df.to_excel(writer, sheet_name=sheet_name, index=False)
            
            print(f"âœ… Excelæ–‡ä»¶ä¿å­˜æˆåŠŸ: {excel_path}")
            
            # ä¿å­˜ä¸ºCSV
            csv_filename = f"truthfulqa_data{CSV_EXTENSION_OUT}"
            csv_path = self.output_dir / csv_filename
            df.to_csv(csv_path, index=False, encoding='utf-8')
            print(f"âœ… CSVæ–‡ä»¶ä¿å­˜æˆåŠŸ: {csv_path}")
            
            # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
            print(f"\nğŸ“ˆ æ•°æ®ç»Ÿè®¡:")
            print(f"   æ€»è®°å½•æ•°: {len(data)}")
            print(f"   åˆ†å‰²åˆ†å¸ƒ:")
            for split in df['split'].unique():
                count = len(df[df['split'] == split])
                print(f"     {split}: {count} æ¡")
            
            # æ˜¾ç¤ºå­—æ®µä¿¡æ¯
            print(f"   æ•°æ®å­—æ®µ:")
            for col in df.columns:
                non_null_count = df[col].notna().sum()
                print(f"     {col}: {non_null_count} æ¡éç©º")
            
            return True
            
        except Exception as e:
            print(f"âŒ ä¿å­˜æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False
